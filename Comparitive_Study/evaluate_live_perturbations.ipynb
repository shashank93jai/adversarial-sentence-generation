{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb9a0093070>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, grad\n",
    "from bleu import compute_bleu\n",
    "from models import load_models, generate\n",
    "from utils import batchify, to_gpu\n",
    "from utils import Corpus, filter_flip_polarity\n",
    "random.seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_DIR = './output/hsieh_bpe_20_epochs'\n",
    "MODEL_DIR = './output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40'\n",
    "DATA_DIR = './data/hsieh_bpe'\n",
    "BATCH_SIZE = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40\n"
     ]
    }
   ],
   "source": [
    "model_args, idx2word, autoencoder, gan_gen, gan_disc, enc_classifier \\\n",
    "        = load_models(MODEL_DIR, suffix=\"_10\", on_gpu=True, arch_cl=\"100\")\n",
    "\n",
    "# not needed\n",
    "del gan_gen\n",
    "del gan_disc\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "word2idx = json.load(open(\"{}/vocab.json\".format(MODEL_DIR), \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./data/hsieh_bpe/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using test.txt as test set\n",
      "Number of sentences cropped from ./data/hsieh_bpe/test.txt: 0 out of 100000 total, dropped 1538. OOV rate 0.000\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus(DATA_DIR,\n",
    "                maxlen=30,\n",
    "                vocab_size=12000,\n",
    "                lowercase=False,\n",
    "                max_lines=100000,\n",
    "                test_size=-1,\n",
    "                load_vocab_file=os.path.join(MODEL_DIR, 'vocab.json'),\n",
    "                test_path='test.txt',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = batchify(corpus.test, bsz=BATCH_SIZE, shuffle=False, pad_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ce = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(sentence_embedding, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_embedding = sentence_embedding + epsilon*sign_data_grad\n",
    "    #clip within normal range for embedding\n",
    "    perturbed_embedding = torch.clamp(perturbed_embedding, -0.34, 0.32)\n",
    "    return perturbed_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, perturb=None, epsilon=.015, alpha=.015, pgd_iters=49):\n",
    "\n",
    "    # perturb can be 'fgsm' or 'pgd' (to apply perturbation live) or None to evaluate without applying any perturbations\n",
    "\n",
    "    all_pred = []\n",
    "    all_tags = []\n",
    "\n",
    "    for i, batch in enumerate(data):\n",
    "        source, target, lengths, tags = batch\n",
    "        source = to_gpu(True, Variable(source))\n",
    "        #target = to_gpu(True, Variable(target)) # word ID\n",
    "        tags = to_gpu(True, Variable(tags))\n",
    "\n",
    "        # autoencoder encoded\n",
    "        output_encode_only = autoencoder(source, lengths, noise=False, encode_only=True)\n",
    "        output_encode_only.retain_grad()  # NL: same as output_encode_only.requires_grad = True\n",
    "\n",
    "        # initial classifier output\n",
    "        output_classifier = enc_classifier(output_encode_only)\n",
    "\n",
    "        # apply perturbation\n",
    "        if perturb == 'fgsm':\n",
    "            classifier_loss = criterion_ce(output_classifier, tags)\n",
    "            enc_classifier.zero_grad()\n",
    "            classifier_loss.backward()\n",
    "            code_grad = output_encode_only.grad.data\n",
    "            perturbed_code = fgsm_attack(output_encode_only, epsilon, code_grad)   \n",
    "\n",
    "            # get classifier predictions on the perturbed code\n",
    "            scores = enc_classifier(perturbed_code)\n",
    "\n",
    "        elif perturb == 'pgd':\n",
    "            # alpha: step size\n",
    "            # epsilon: max perturbation (ball)\n",
    "            perturbed_code = output_encode_only.clone().detach()\n",
    "            for i in range(pgd_iters):\n",
    "                perturbed_code.requires_grad = True\n",
    "                scores = enc_classifier(perturbed_code)\n",
    "                tmp_loss = criterion_ce(scores, tags)\n",
    "                enc_classifier.zero_grad()\n",
    "                tmp_loss.backward(retain_graph=True)\n",
    "\n",
    "                # step in the direction of the gradient\n",
    "                perturbed_code = perturbed_code + alpha * perturbed_code.grad.sign()\n",
    "\n",
    "                # Workaround as PyTorch doesn't have elementwise clip\n",
    "                # from: https://gist.github.com/oscarknagg/45b187c236c6262b1c4bbe2d0920ded6#file-projected_gradient_descent-py\n",
    "                perturbed_code = torch.max(torch.min(perturbed_code, output_encode_only + epsilon), output_encode_only - epsilon).detach()\n",
    "                perturbed_code = torch.clamp(perturbed_code, -0.34, 0.32)\n",
    "\n",
    "            # get classifier predictions on the perturbed code\n",
    "            scores = enc_classifier(perturbed_code)\n",
    "\n",
    "        else:\n",
    "            scores = output_classifier\n",
    "\n",
    "        # get preds\n",
    "        _, output_classifier_argmax = torch.max(scores, -1)\n",
    "        pred = output_classifier_argmax.cpu().numpy()\n",
    "        \n",
    "        all_pred.extend(pred)\n",
    "        all_tags.extend(tags.cpu().numpy())\n",
    "        \n",
    "    #return all_tags\n",
    "    accuracy = (np.array(all_pred) == np.array(all_tags)).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9791986186582703\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_model(test_data, perturb=None)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM: Epsilon 0.001, Acc: 0.9743943933776852\n",
      "FGSM: Epsilon 0.006, Acc: 0.9312680920217358\n",
      "FGSM: Epsilon 0.011, Acc: 0.8109999492153775\n",
      "FGSM: Epsilon 0.016, Acc: 0.43640241734802704\n",
      "FGSM: Epsilon 0.021, Acc: 0.0631862272104007\n",
      "FGSM: Epsilon 0.026, Acc: 0.0024275049515006856\n",
      "FGSM: Epsilon 0.031, Acc: 8.125539586613174e-05\n",
      "FGSM: Epsilon 0.036, Acc: 1.0156924483266467e-05\n",
      "FGSM: Epsilon 0.041, Acc: 2.0313848966532935e-05\n",
      "FGSM: Epsilon 0.046, Acc: 2.0313848966532935e-05\n",
      "FGSM: Epsilon 0.051, Acc: 2.0313848966532935e-05\n",
      "FGSM: Epsilon 0.056, Acc: 2.0313848966532935e-05\n",
      "FGSM: Epsilon 0.061, Acc: 2.0313848966532935e-05\n",
      "FGSM: Epsilon 0.066, Acc: 1.0156924483266467e-05\n",
      "FGSM: Epsilon 0.071, Acc: 0.0\n",
      "FGSM: Epsilon 0.076, Acc: 0.0\n",
      "FGSM: Epsilon 0.081, Acc: 1.0156924483266467e-05\n",
      "FGSM: Epsilon 0.086, Acc: 0.0\n",
      "FGSM: Epsilon 0.091, Acc: 1.0156924483266467e-05\n",
      "FGSM: Epsilon 0.096, Acc: 1.0156924483266467e-05\n"
     ]
    }
   ],
   "source": [
    "eps_range = [np.round(x, 3) for x in np.arange(1e-3, 1e-1, 5e-3)]\n",
    "for epsilon in eps_range:\n",
    "    acc = evaluate_model(test_data, perturb='fgsm', epsilon=epsilon)\n",
    "    print('FGSM: Epsilon {}, Acc: {}'.format(epsilon, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 5, Acc: 0.9428063582347265\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 10, Acc: 0.8353257833528007\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 20, Acc: 0.084505611700777\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 40, Acc: 0.0\n"
     ]
    }
   ],
   "source": [
    "configs = [(0.05, 0.001, 5), (0.05, 0.001, 10), (0.05, 0.001, 20), (0.05, 0.001, 40)]\n",
    "for epsilon, alpha, pgd_iters in configs:\n",
    "    acc = evaluate_model(test_data, perturb='pgd', epsilon=epsilon, alpha=alpha, pgd_iters=pgd_iters)\n",
    "    print('PGD: Epsilon {} Alpha {} Steps {}, Acc: {}'.format(epsilon, alpha, pgd_iters, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([ 4.6077, 11.8412, 13.5215,  1.4843,  1.1130,  3.2549,  6.2035,  7.7105,\n",
       "        11.6899,  0.6113, 14.4979,  4.6565,  2.5570,  0.9846,  8.5023, 10.7292,\n",
       "         1.6135,  3.4619,  4.2871,  2.6490,  1.6265,  3.2528,  3.6785,  2.4603,\n",
       "         3.2518,  1.9567,  3.4394,  2.5880,  1.9504,  1.0755,  2.2231,  4.9804,\n",
       "         0.8627,  1.8109,  3.7487], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(scores, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 3])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9770555075923011\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(test_data, perturb='fgsm', epsilon=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-f94fd8a5996c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpgd_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-8ff80b80ea0d>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(data, perturb, epsilon, alpha, pgd_iters)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mperturbed_code\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mtmp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0menc_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mtmp_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(test_data, perturb='pgd', epsilon=0, alpha=.01, pgd_iters=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9772383322329998\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Testing FGSM trained model, epsilon=0.016</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9779391600223453\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_model(test_data, perturb=None)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM: Epsilon 0.001, Acc: 0.9776953938347468\n",
      "FGSM: Epsilon 0.006, Acc: 0.9754608704484282\n",
      "FGSM: Epsilon 0.011, Acc: 0.9738459194555888\n",
      "FGSM: Epsilon 0.016, Acc: 0.9718551622568686\n",
      "FGSM: Epsilon 0.021, Acc: 0.966339952262455\n",
      "FGSM: Epsilon 0.026, Acc: 0.9280483469605404\n",
      "FGSM: Epsilon 0.031, Acc: 0.7972779442384846\n",
      "FGSM: Epsilon 0.036, Acc: 0.6343202478289574\n",
      "FGSM: Epsilon 0.041, Acc: 0.5017114417754304\n",
      "FGSM: Epsilon 0.046, Acc: 0.4060027423696105\n",
      "FGSM: Epsilon 0.051, Acc: 0.33819511451932355\n",
      "FGSM: Epsilon 0.056, Acc: 0.28439388553146105\n",
      "FGSM: Epsilon 0.061, Acc: 0.24567568940124931\n",
      "FGSM: Epsilon 0.066, Acc: 0.21379310344827587\n",
      "FGSM: Epsilon 0.071, Acc: 0.19328627291656086\n",
      "FGSM: Epsilon 0.076, Acc: 0.177319587628866\n",
      "FGSM: Epsilon 0.081, Acc: 0.17083946980854198\n",
      "FGSM: Epsilon 0.086, Acc: 0.16199278858361688\n",
      "FGSM: Epsilon 0.091, Acc: 0.16236859478949775\n",
      "FGSM: Epsilon 0.096, Acc: 0.1595652836321162\n"
     ]
    }
   ],
   "source": [
    "eps_range = [np.round(x, 3) for x in np.arange(1e-3, 1e-1, 5e-3)]\n",
    "for epsilon in eps_range:\n",
    "    acc = evaluate_model(test_data, perturb='fgsm', epsilon=epsilon)\n",
    "    print('FGSM: Epsilon {}, Acc: {}'.format(epsilon, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 5, Acc: 0.9757249504849932\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 10, Acc: 0.9737138794373064\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 20, Acc: 0.9661571276217561\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 40, Acc: 0.09222487430805952\n"
     ]
    }
   ],
   "source": [
    "configs = [(0.05, 0.001, 5), (0.05, 0.001, 10), (0.05, 0.001, 20), (0.05, 0.001, 40)]\n",
    "for epsilon, alpha, pgd_iters in configs:\n",
    "    acc = evaluate_model(test_data, perturb='pgd', epsilon=epsilon, alpha=alpha, pgd_iters=pgd_iters)\n",
    "    print('PGD: Epsilon {} Alpha {} Steps {}, Acc: {}'.format(epsilon, alpha, pgd_iters, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Testing PGD trained model, hsieh_bpe_20_epochs_pgd_0.05_0.001_40 </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9774008430247321\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate_model(test_data, perturb=None)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM: Epsilon 0.001, Acc: 0.9766086029150374\n",
      "FGSM: Epsilon 0.006, Acc: 0.9729317962520949\n",
      "FGSM: Epsilon 0.011, Acc: 0.9689502818546544\n",
      "FGSM: Epsilon 0.016, Acc: 0.9638921334619877\n",
      "FGSM: Epsilon 0.021, Acc: 0.958183941902392\n",
      "FGSM: Epsilon 0.026, Acc: 0.9525874765121122\n",
      "FGSM: Epsilon 0.031, Acc: 0.9451729216393276\n",
      "FGSM: Epsilon 0.036, Acc: 0.9361637296226702\n",
      "FGSM: Epsilon 0.041, Acc: 0.9260982174597532\n",
      "FGSM: Epsilon 0.046, Acc: 0.9148646589812605\n",
      "FGSM: Epsilon 0.051, Acc: 0.8990604844852979\n",
      "FGSM: Epsilon 0.056, Acc: 0.8816210451475294\n",
      "FGSM: Epsilon 0.061, Acc: 0.8597227159616069\n",
      "FGSM: Epsilon 0.066, Acc: 0.8305723426946321\n",
      "FGSM: Epsilon 0.071, Acc: 0.7955309532273628\n",
      "FGSM: Epsilon 0.076, Acc: 0.7532781473769743\n",
      "FGSM: Epsilon 0.081, Acc: 0.7050632268549083\n",
      "FGSM: Epsilon 0.086, Acc: 0.6491595144990097\n",
      "FGSM: Epsilon 0.091, Acc: 0.5908282971916103\n",
      "FGSM: Epsilon 0.096, Acc: 0.5292671778985323\n"
     ]
    }
   ],
   "source": [
    "eps_range = [np.round(x, 3) for x in np.arange(1e-3, 1e-1, 5e-3)]\n",
    "for epsilon in eps_range:\n",
    "    acc = evaluate_model(test_data, perturb='fgsm', epsilon=epsilon)\n",
    "    print('FGSM: Epsilon {}, Acc: {}'.format(epsilon, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 5, Acc: 0.9735412117210909\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 10, Acc: 0.9691127926463867\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 20, Acc: 0.9596973236503986\n",
      "PGD: Epsilon 0.05 Alpha 0.001 Steps 40, Acc: 0.9277741099994922\n"
     ]
    }
   ],
   "source": [
    "configs = [(0.05, 0.001, 5), (0.05, 0.001, 10), (0.05, 0.001, 20), (0.05, 0.001, 40)]\n",
    "for epsilon, alpha, pgd_iters in configs:\n",
    "    acc = evaluate_model(test_data, perturb='pgd', epsilon=epsilon, alpha=alpha, pgd_iters=pgd_iters)\n",
    "    print('PGD: Epsilon {} Alpha {} Steps {}, Acc: {}'.format(epsilon, alpha, pgd_iters, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
