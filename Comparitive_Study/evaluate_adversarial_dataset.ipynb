{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcb14062070>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, grad\n",
    "from bleu import compute_bleu\n",
    "from models import load_models, generate\n",
    "from utils import batchify, to_gpu\n",
    "from utils import Corpus, filter_flip_polarity\n",
    "random.seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = './output/hsieh_bpe_20_epochs'\n",
    "# MODEL_DIR = './output/hsieh_bpe_20_epochs_fgsm_0.016'\n",
    "# MODEL_DIR = './output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40'\n",
    "DATA_DIR = './data/hsieh_bpe'\n",
    "ADVERSARIAL_DATA_DIR = './adversarial_data'\n",
    "BATCH_SIZE = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from./output/hsieh_bpe_20_epochs\n"
     ]
    }
   ],
   "source": [
    "model_args, idx2word, autoencoder, gan_gen, gan_disc, enc_classifier \\\n",
    "        = load_models(MODEL_DIR, suffix=\"_10\", on_gpu=True, arch_cl=\"100\")\n",
    "\n",
    "# not needed\n",
    "del gan_gen\n",
    "del gan_disc\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "word2idx = json.load(open(\"{}/vocab.json\".format(MODEL_DIR), \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_ce = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(sentence_embedding, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_embedding = sentence_embedding + epsilon*sign_data_grad\n",
    "    #clip within normal range for embedding\n",
    "    perturbed_embedding = torch.clamp(perturbed_embedding, -0.34, 0.32)\n",
    "    return perturbed_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data, perturb=None, epsilon=.015, alpha=.015, pgd_iters=49, return_pred_and_tags=False):\n",
    "\n",
    "    # perturb can be 'fgsm' or 'pgd' (to apply perturbation live) or None to evaluate without applying any perturbations\n",
    "\n",
    "    all_pred = []\n",
    "    all_tags = []\n",
    "\n",
    "    for i, batch in enumerate(data):\n",
    "        source, target, lengths, tags = batch\n",
    "        source = to_gpu(True, Variable(source))\n",
    "        #target = to_gpu(True, Variable(target)) # word ID\n",
    "        tags = to_gpu(True, Variable(tags))\n",
    "\n",
    "        # autoencoder encoded\n",
    "        output_encode_only = autoencoder(source, lengths, noise=False, encode_only=True)\n",
    "        output_encode_only.retain_grad()  # NL: same as output_encode_only.requires_grad = True\n",
    "\n",
    "        # initial classifier output\n",
    "        output_classifier = enc_classifier(output_encode_only)\n",
    "\n",
    "        # apply perturbation\n",
    "        if perturb == 'fgsm':\n",
    "            classifier_loss = criterion_ce(output_classifier, tags)\n",
    "            enc_classifier.zero_grad()\n",
    "            classifier_loss.backward()\n",
    "            code_grad = output_encode_only.grad.data\n",
    "            perturbed_code = fgsm_attack(output_encode_only, epsilon, code_grad)   \n",
    "\n",
    "            # get classifier predictions on the perturbed code\n",
    "            scores = enc_classifier(perturbed_code)\n",
    "\n",
    "        elif perturb == 'pgd':\n",
    "            # alpha: step size\n",
    "            # epsilon: max perturbation (ball)\n",
    "            perturbed_code = output_encode_only.clone().detach()\n",
    "            for i in range(pgd_iters):\n",
    "                perturbed_code.requires_grad = True\n",
    "                scores = enc_classifier(perturbed_code)\n",
    "                tmp_loss = criterion_ce(scores, tags)\n",
    "                enc_classifier.zero_grad()\n",
    "                tmp_loss.backward(retain_graph=True)\n",
    "\n",
    "                # step in the direction of the gradient\n",
    "                perturbed_code = perturbed_code + alpha * perturbed_code.grad.sign()\n",
    "\n",
    "                # Workaround as PyTorch doesn't have elementwise clip\n",
    "                # from: https://gist.github.com/oscarknagg/45b187c236c6262b1c4bbe2d0920ded6#file-projected_gradient_descent-py\n",
    "                perturbed_code = torch.max(torch.min(perturbed_code, output_encode_only + epsilon), output_encode_only - epsilon).detach()\n",
    "                perturbed_code = torch.clamp(perturbed_code, -0.34, 0.32)\n",
    "\n",
    "            # get classifier predictions on the perturbed code\n",
    "            scores = enc_classifier(perturbed_code)\n",
    "\n",
    "        else:\n",
    "            scores = output_classifier\n",
    "\n",
    "        # get preds\n",
    "        _, output_classifier_argmax = torch.max(scores, -1)\n",
    "        pred = output_classifier_argmax.cpu().numpy()\n",
    "        \n",
    "        all_pred.extend(pred)\n",
    "        all_tags.extend(tags.cpu().numpy())\n",
    "        \n",
    "    #return all_tags\n",
    "    accuracy = (np.array(all_pred) == np.array(all_tags)).mean()\n",
    "    \n",
    "    if return_pred_and_tags:\n",
    "        return accuracy, all_pred, all_tags\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.8922268907563026\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.8500331198940163\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.7885605338417541\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.6942713154376221\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.5606738705011487\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.4089927789771458\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.28800270819228163\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.2107780612244898\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.16256410256410256\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.12909659526759898\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.10485392224522659\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.08503670242800677\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.07105599733081243\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.05800132071318512\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.0494824016563147\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.04075455380790228\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.03309514855208725\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.027920136664531282\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.023632501327668615\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.019407407407407408\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hack since corpus needs train.txt\n",
    "from shutil import copyfile\n",
    "copyfile(DATA_DIR + '/train.txt', ADVERSARIAL_DATA_DIR+'/train.txt')\n",
    "\n",
    "\n",
    "filenames = [filename for filename in os.listdir(ADVERSARIAL_DATA_DIR) if filename.endswith(\".txt\") and filename != 'train.txt']\n",
    "filenames.sort()\n",
    "\n",
    "for filename in filenames:\n",
    "    epsilon = filename.split(' ')[1].split('_')[1]\n",
    "    corpus = Corpus(ADVERSARIAL_DATA_DIR,\n",
    "            maxlen=30,\n",
    "            vocab_size=12000,\n",
    "            lowercase=False,\n",
    "            max_lines=100000,\n",
    "            test_size=-1,\n",
    "            load_vocab_file=os.path.join(MODEL_DIR, 'vocab.json'),\n",
    "            test_path=filename,)\n",
    "\n",
    "    test_data = batchify(corpus.test, bsz=BATCH_SIZE, shuffle=False, pad_id=0)\n",
    "    acc = evaluate_model(test_data, perturb = None)\n",
    "    print('Epsilon {}, Acc {}'.format(epsilon, acc))\n",
    "    print('\\n')\n",
    "    #if filename.endswith(\".asm\") or filename.endswith(\".py\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluating on FGSM trained model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.8947478991596639\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.84707440936189\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.7871714558082528\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.691062429291371\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.5560622819705607\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.40521104742053154\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.2848882870683819\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.20860969387755102\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.16084249084249083\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.12771581990912845\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.10410628019323671\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.08313946922642575\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.06983261969637991\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.05607528065155184\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.04789146779993462\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.039219501648559536\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.032396711975500994\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.027386290839205636\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.02300584174190122\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_fgsm_0.016/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.018952380952380953\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hack since corpus needs train.txt\n",
    "from shutil import copyfile\n",
    "copyfile(DATA_DIR + '/train.txt', ADVERSARIAL_DATA_DIR+'/train.txt')\n",
    "\n",
    "\n",
    "filenames = [filename for filename in os.listdir(ADVERSARIAL_DATA_DIR) if filename.endswith(\".txt\") and filename != 'train.txt']\n",
    "filenames.sort()\n",
    "\n",
    "for filename in filenames:\n",
    "    epsilon = filename.split(' ')[1].split('_')[1]\n",
    "    corpus = Corpus(ADVERSARIAL_DATA_DIR,\n",
    "            maxlen=30,\n",
    "            vocab_size=12000,\n",
    "            lowercase=False,\n",
    "            max_lines=100000,\n",
    "            test_size=-1,\n",
    "            load_vocab_file=os.path.join(MODEL_DIR, 'vocab.json'),\n",
    "            test_path=filename,)\n",
    "\n",
    "    test_data = batchify(corpus.test, bsz=BATCH_SIZE, shuffle=False, pad_id=0)\n",
    "    acc = evaluate_model(test_data, perturb = None)\n",
    "    print('Epsilon {}, Acc {}'.format(epsilon, acc))\n",
    "    print('\\n')\n",
    "    #if filename.endswith(\".asm\") or filename.endswith(\".py\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Evaluating on PGD trained model, hsieh_bpe_20_epochs_pgd_0.05_0.001_40</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.8968487394957984\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.8469419297858247\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.7872259294566254\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.6915972436490795\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.5572194333361695\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.40530037966202637\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.2853215978334462\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.20839285714285713\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.16034188034188035\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.12811707086800023\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.10411778237865195\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.08315076228119707\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.06953233609520103\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.0561303103675985\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.04725945298027678\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.03866818009837306\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.031193252028152367\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.026468076019645525\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.022113648433351035\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.018222222222222223\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hack since corpus needs train.txt\n",
    "from shutil import copyfile\n",
    "copyfile(DATA_DIR + '/train.txt', ADVERSARIAL_DATA_DIR+'/train.txt')\n",
    "\n",
    "\n",
    "filenames = [filename for filename in os.listdir(ADVERSARIAL_DATA_DIR) if filename.endswith(\".txt\") and filename != 'train.txt']\n",
    "filenames.sort()\n",
    "\n",
    "for filename in filenames:\n",
    "    epsilon = filename.split(' ')[1].split('_')[1]\n",
    "    corpus = Corpus(ADVERSARIAL_DATA_DIR,\n",
    "            maxlen=30,\n",
    "            vocab_size=12000,\n",
    "            lowercase=False,\n",
    "            max_lines=100000,\n",
    "            test_size=-1,\n",
    "            load_vocab_file=os.path.join(MODEL_DIR, 'vocab.json'),\n",
    "            test_path=filename,)\n",
    "\n",
    "    test_data = batchify(corpus.test, bsz=BATCH_SIZE, shuffle=False, pad_id=0)\n",
    "    acc = evaluate_model(test_data, perturb = None)\n",
    "    print('Epsilon {}, Acc {}'.format(epsilon, acc))\n",
    "    print('\\n')\n",
    "    #if filename.endswith(\".asm\") or filename.endswith(\".py\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on nonrobust model's classification errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each adversarial dataset, get the indices of test examples that were misclassified by the non-robust model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models from./output/hsieh_bpe_20_epochs\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.8913043478260869\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.8473086943082969\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.7860758804637744\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.692420034968631\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.5564571000884534\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.40613973708109397\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.2855305553299218\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.20856603677351898\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.16144078144078144\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.12789929449517473\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.10435542473439728\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.08449893317980153\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.07018382802682355\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.056840437471117666\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.048184502086215726\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.03958063121487246\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.03237448709961546\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.026817837278074925\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.022696617280016994\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.019083686832890797\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "after_epochs = \"_20\"\n",
    "\n",
    "model_args, idx2word, autoencoder, gan_gen, gan_disc, enc_classifier \\\n",
    "        = load_models(MODEL_DIR, suffix=after_epochs, on_gpu=True, arch_cl=\"100\")\n",
    "\n",
    "# not needed\n",
    "del gan_gen\n",
    "del gan_disc\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "word2idx = json.load(open(\"{}/vocab.json\".format(MODEL_DIR), \"r\"))\n",
    "\n",
    "\n",
    "\n",
    "#hack since corpus needs train.txt\n",
    "from shutil import copyfile\n",
    "copyfile(DATA_DIR + '/train.txt', ADVERSARIAL_DATA_DIR+'/train.txt')\n",
    "\n",
    "filenames = [filename for filename in os.listdir(ADVERSARIAL_DATA_DIR) if filename.endswith(\".txt\") and filename != 'train.txt']\n",
    "filenames.sort()\n",
    "\n",
    "misclassified_data = dict()\n",
    "\n",
    "for filename in filenames:\n",
    "    epsilon = filename.split(' ')[1].split('_')[1]\n",
    "    corpus = Corpus(ADVERSARIAL_DATA_DIR,\n",
    "            maxlen=30,\n",
    "            vocab_size=12000,\n",
    "            lowercase=False,\n",
    "            max_lines=100000,\n",
    "            test_size=-1,\n",
    "            load_vocab_file=os.path.join(MODEL_DIR, 'vocab.json'),\n",
    "            test_path=filename,)\n",
    "\n",
    "    test_data = batchify(corpus.test, bsz=1, shuffle=False, pad_id=0)\n",
    "    acc, pred, tags = evaluate_model(test_data, perturb = None, return_pred_and_tags=True)\n",
    "    misclassified_data[filename] = [np.array(pred) != np.array(tags)]\n",
    "    print('Epsilon {}, Acc {}'.format(epsilon, acc))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy of the misclassified examples from each adv. dataset against each of the adversarially trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " == ./output/hsieh_bpe_20_epochs ==\n",
      "\n",
      "Loading models from./output/hsieh_bpe_20_epochs\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.022448979591836733\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.0239067055393586\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.020153061224489795\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.015122114419538308\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.009702780441035475\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.007374890254609306\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.005346478339179069\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.004898880025783579\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.004325032765399738\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.003260281385281385\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.002953451043338684\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.002466243294901042\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.0022014836085187846\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.002006649944583795\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.0016712454212454212\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.0014409546324439942\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.0012547887402143134\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.0010862409479921\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.0008476878769765799\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.0006471444750040447\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " == ./output/hsieh_bpe_20_epochs_fgsm_0.016 ==\n",
      "\n",
      "Loading models from./output/hsieh_bpe_20_epochs_fgsm_0.016\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.13673469387755102\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.10991253644314869\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.09298469387755103\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.06865172298427567\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.052080536912751677\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.039232409381663114\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.030126078301260784\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.024381596970429457\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.020256298237949614\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.01764069264069264\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.016269662921348314\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.014008261915037918\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.01265853074898301\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.011188240097999184\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.009741300366300366\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.008443093549476529\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.00766198434290156\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.006802721088435374\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.006140303211432919\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.005015369681281346\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " == ./output/hsieh_bpe_20_epochs_fgsm_0.051 ==\n",
      "\n",
      "Loading models from./output/hsieh_bpe_20_epochs_fgsm_0.051\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.1653061224489796\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.11574344023323616\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.09566326530612244\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.07420541987286718\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.05534036433365292\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.04108867427568042\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.033197459474831735\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.02770123277737491\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.023591087811271297\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.020468073593073594\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.018786516853932584\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.015253714778962944\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.014848049772672888\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.012914892375896868\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.01130952380952381\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.01006416751097602\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.00953861529065571\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.008174237436910248\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.0077487366190295065\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.006288087148789301\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " == ./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40 ==\n",
      "\n",
      "Loading models from./output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.001 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.001 test.txt: 0 out of 4784 total, dropped 0. OOV rate 0.000\n",
      "Epsilon 0.001, Acc 0.1346938775510204\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.006 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.006 test.txt: 0 out of 22655 total, dropped 8. OOV rate 0.000\n",
      "Epsilon 0.006, Acc 0.11574344023323616\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.011 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.011 test.txt: 0 out of 36754 total, dropped 12. OOV rate 0.000\n",
      "Epsilon 0.011, Acc 0.09285714285714286\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.016 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.016 test.txt: 0 out of 48636 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.016, Acc 0.06651053864168618\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.021 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.021 test.txt: 0 out of 58809 total, dropped 21. OOV rate 0.000\n",
      "Epsilon 0.021, Acc 0.04928092042186002\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.026 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.026 test.txt: 0 out of 67197 total, dropped 28. OOV rate 0.000\n",
      "Epsilon 0.026, Acc 0.03464191646807977\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.031 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.031 test.txt: 0 out of 73895 total, dropped 29. OOV rate 0.000\n",
      "Epsilon 0.031, Acc 0.026466963693241065\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.036 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.036 test.txt: 0 out of 78464 total, dropped 38. OOV rate 0.000\n",
      "Epsilon 0.036, Acc 0.021754894851341553\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.041 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.041 test.txt: 0 out of 81947 total, dropped 47. OOV rate 0.000\n",
      "Epsilon 0.041, Acc 0.01766419105868647\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.046 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.046 test.txt: 0 out of 84810 total, dropped 48. OOV rate 0.000\n",
      "Epsilon 0.046, Acc 0.01608495670995671\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.051 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.051 test.txt: 0 out of 87033 total, dropped 61. OOV rate 0.000\n",
      "Epsilon 0.051, Acc 0.014240770465489567\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.056 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.056 test.txt: 0 out of 88649 total, dropped 68. OOV rate 0.000\n",
      "Epsilon 0.056, Acc 0.012602503236944325\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.061 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.061 test.txt: 0 out of 89999 total, dropped 78. OOV rate 0.000\n",
      "Epsilon 0.061, Acc 0.011354391002632209\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.066 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.066 test.txt: 0 out of 90963 total, dropped 77. OOV rate 0.000\n",
      "Epsilon 0.066, Acc 0.010103249139590504\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.071 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.071 test.txt: 0 out of 91883 total, dropped 90. OOV rate 0.000\n",
      "Epsilon 0.071, Acc 0.009031593406593406\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.076 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.076 test.txt: 0 out of 92601 total, dropped 81. OOV rate 0.000\n",
      "Epsilon 0.076, Acc 0.007767646065518406\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.081 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.081 test.txt: 0 out of 93180 total, dropped 82. OOV rate 0.000\n",
      "Epsilon 0.081, Acc 0.006529343179168286\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.086 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.086 test.txt: 0 out of 93757 total, dropped 88. OOV rate 0.000\n",
      "Epsilon 0.086, Acc 0.00597981127935045\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.091 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.091 test.txt: 0 out of 94235 total, dropped 80. OOV rate 0.000\n",
      "Epsilon 0.091, Acc 0.00558604575340977\n",
      "\n",
      "\n",
      "Loaded vocab file ./output/hsieh_bpe_20_epochs/vocab.json with 5971 words\n",
      "Number of sentences cropped from ./adversarial_data/train.txt: 0 out of 100000 total, dropped 1517. OOV rate 0.000\n",
      "Using fgsm eps_0.096 test.txt as test set\n",
      "Number of sentences cropped from ./adversarial_data/fgsm eps_0.096 test.txt: 0 out of 94610 total, dropped 79. OOV rate 0.000\n",
      "Epsilon 0.096, Acc 0.004335867982527099\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models_to_evaluate = [\n",
    "    './output/hsieh_bpe_20_epochs',\n",
    "    './output/hsieh_bpe_20_epochs_fgsm_0.016',\n",
    "    './output/hsieh_bpe_20_epochs_fgsm_0.051',\n",
    "    './output/hsieh_bpe_20_epochs_pgd_0.05_0.001_40',\n",
    "]\n",
    "\n",
    "\n",
    "for model_dir in models_to_evaluate:\n",
    "    print(\"\\n\\n ==\", model_dir, \"==\\n\")\n",
    "    model_args, idx2word, autoencoder, gan_gen, gan_disc, enc_classifier \\\n",
    "            = load_models(model_dir, suffix=after_epochs, on_gpu=True, arch_cl=\"100\")\n",
    "\n",
    "    # not needed\n",
    "    del gan_gen\n",
    "    del gan_disc\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    word2idx = json.load(open(\"{}/vocab.json\".format(MODEL_DIR), \"r\"))\n",
    "\n",
    "    # load adversarial datasets, but only the indices where the non-robust model\n",
    "    # made classification errors\n",
    "    for filename in filenames:\n",
    "        epsilon = filename.split(' ')[1].split('_')[1]\n",
    "        corpus = Corpus(ADVERSARIAL_DATA_DIR,\n",
    "                maxlen=30,\n",
    "                vocab_size=12000,\n",
    "                lowercase=False,\n",
    "                max_lines=100000,\n",
    "                test_size=-1,\n",
    "                load_vocab_file=os.path.join(MODEL_DIR, 'vocab.json'),\n",
    "                test_path=filename)\n",
    "\n",
    "        test_data = batchify(list(np.array(corpus.test)[misclassified_data[filename][0]]),\n",
    "                             bsz=BATCH_SIZE, shuffle=False, pad_id=0)        \n",
    "        \n",
    "        acc = evaluate_model(test_data, perturb = None)\n",
    "        print('Epsilon {}, Acc {}'.format(epsilon, acc))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
