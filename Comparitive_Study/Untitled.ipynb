{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f6890051670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, grad\n",
    "from bleu import compute_bleu\n",
    "from models import load_models, generate\n",
    "from utils import batchify, to_gpu\n",
    "from utils import Corpus, filter_flip_polarity\n",
    "random.seed(1111)\n",
    "np.random.seed(1111)\n",
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test this .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_separators(sent):\n",
    "    return sent.replace(\"@@ \", \"\")\n",
    "\n",
    "def to_BPE(sent):\n",
    "    p = Popen(['python', 'bytepairencoding/apply_bpe.py', \"--codes\", \"bytepairencoding/bpecode_yelp\"], stdout=PIPE, stdin=PIPE, stderr=STDOUT)\n",
    "    grep_stdout = p.communicate(input=sent.encode('utf-8'))[0]\n",
    "    return grep_stdout.decode('utf-8')\n",
    "\n",
    "remove_separators(to_BPE(\"Test this .\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_from(test_sentence, num_output=10):\n",
    "    # autoencoder.hidden_init = True\n",
    "    test_sentence = to_BPE(test_sentence).split(' ')\n",
    "    test_sentence = ['<sos>'] + test_sentence\n",
    "#     test_sentence_ids = [word2idx[w] if w in word2idx else word2idx['<oov>'] for w in test_sentence]\n",
    "    test_sentence_ids = [word2idx[w] for w in test_sentence]\n",
    "    indices = to_gpu(True, Variable(torch.LongTensor([test_sentence_ids])))\n",
    "    lengths = [len(test_sentence),]\n",
    "    \n",
    "    sentences = []\n",
    "    classes = []\n",
    "    hh = autoencoder.encode(indices, lengths=lengths, noise=False)\n",
    "    original_class = enc_classifier(hh)\n",
    "    original_class = torch.max(original_class, -1)[1].data.cpu().numpy()\n",
    "    for times in range(num_output):\n",
    "        hh = autoencoder.encode(indices, lengths=lengths, noise=True)\n",
    "        cc = enc_classifier(hh)\n",
    "        _, cc = torch.max(cc, -1)\n",
    "        cc = \"{}\".format(cc.data.cpu().numpy())\n",
    "        max_indices = autoencoder.generate(hidden=hh, maxlen=30, sample=False)\n",
    "        max_indices = max_indices.data.cpu().numpy()\n",
    "        \n",
    "        for idx in max_indices:\n",
    "            # generated sentence\n",
    "            words = [idx2word[x] for x in idx]\n",
    "            # truncate sentences to first occurrence of <eos>\n",
    "            truncated_sent = []\n",
    "            for w in words:\n",
    "                if w != '<eos>':\n",
    "                    truncated_sent.append(w)\n",
    "                else:\n",
    "                    break\n",
    "        sent = \" \".join(truncated_sent)\n",
    "        sentences.append(sent)\n",
    "        classes.append(cc)\n",
    "    return sentences, classes, original_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adv(hidden):\n",
    "    max_indices = autoencoder.generate(hidden=hidden, maxlen=30, sample=False)\n",
    "    max_indices = max_indices.data.cpu().numpy()\n",
    "    for idx in max_indices:\n",
    "        # generated sentence\n",
    "        words = [idx2word[x] for x in idx]\n",
    "        # truncate sentences to first occurrence of <eos>\n",
    "        truncated_sent = []\n",
    "        for w in words:\n",
    "            if w != '<eos>':\n",
    "                truncated_sent.append(w)\n",
    "            else:\n",
    "                break\n",
    "    sent = \" \".join(truncated_sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = './output/example_forEMNLP'\n",
    "model_args, idx2word, autoencoder, gan_gen, gan_disc, enc_classifier \\\n",
    "        = load_models(load_path, suffix=\"_10\", on_gpu=True)\n",
    "word2idx = json.load(open(\"{}/vocab.json\".format(load_path), \"r\"))\n",
    "autoencoder.cuda()\n",
    "enc_classifier.cuda()\n",
    "autoencoder.gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_classifier.zero_grad()\n",
    "autoencoder.zero_grad()\n",
    "\n",
    "test_sentence = \"The chicken is good , but the rest of the food is even better .\"\n",
    "# test_sentence = \"Long line , inefficient staff . Maybe my expectations were too high but it just was n't as good as I was hoping for the calories .\"\n",
    "# test_sentence = \"enjoyed obviously cinnamon believe markt likely enjoyed creepy average specifically brazil gets primarily reality markt likely believe ich primarily brazil meh written too follow reality lover buy expectations likely dedicated condescending mediocre\"\n",
    "# test_sentence = \"A steakhouse can not deliver quality steak , which is unacceptable . Part of the steak was made carbonized , barely edible .\"\n",
    "# test_sentence = \"I love this place ! It 's walking distance from my office that service delicious fast food . It 's a great place to grab a quick freshly made breakfast\"\n",
    "# test_sentence = \"It was not the worse restaurant I 've ever had in a food place for over 20 months and our server was exquissive nothing like shit .\"\n",
    "\n",
    "test_sentence = to_BPE(test_sentence).split(' ')\n",
    "test_sentence = ['<sos>'] + test_sentence\n",
    "test_sentence_ids = [word2idx[w] for w in test_sentence]\n",
    "indices = to_gpu(True, Variable(torch.LongTensor([test_sentence_ids])))\n",
    "lengths = [len(test_sentence)]\n",
    "\n",
    "hh = autoencoder(indices, lengths=lengths, noise=False, encode_only=True)\n",
    "classifier_out = enc_classifier(hh)\n",
    "classifier_out.retain_grad()\n",
    "hh.retain_grad()\n",
    "classifier_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 5e-2\n",
    "x_adversarial = to_gpu(True, Variable(hh - epsilon * encoder_output_grad, requires_grad=False))\n",
    "max_indices = autoencoder.generate(hidden=x_adversarial, maxlen=30, sample=False)\n",
    "max_indices = max_indices.data.cpu().numpy()\n",
    "\n",
    "for idx in max_indices:\n",
    "    # generated sentence\n",
    "    words = [idx2word[x] for x in idx]\n",
    "    # truncate sentences to first occurrence of <eos>\n",
    "    truncated_sent = []\n",
    "    for w in words:\n",
    "        if w != '<eos>':\n",
    "            truncated_sent.append(w)\n",
    "        else:\n",
    "            break\n",
    "sent = \" \".join(truncated_sent)\n",
    "print(remove_separators(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(\"./processed_yelp/\",\n",
    "                maxlen=30,\n",
    "                vocab_size=12000,\n",
    "                lowercase=False,\n",
    "                max_lines=100000,\n",
    "                test_size=-1,\n",
    "                load_vocab_file='./output/example/vocab.json',\n",
    "                test_path='test.txt',)\n",
    "ntokens = len(corpus.dictionary.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz=35\n",
    "f_test = filter_flip_polarity(corpus.test)\n",
    "test_data = batchify(f_test, bsz=bsz, shuffle=False, pad_id=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test a range of epsilon values for generation\n",
    "criterion_ce = nn.CrossEntropyLoss().cuda()\n",
    "eps_range = map(float, np.arange(1e-3, 1e-1, 2e-3))\n",
    "# eps_range = [0.015]\n",
    "real_sent_printed = False\n",
    "original_sentences = []\n",
    "changed_sentences = []\n",
    "\n",
    "for epsilon in eps_range:\n",
    "\n",
    "    all_accuracies = 0.\n",
    "    word_accuracies = 0.\n",
    "    bleus = 0.\n",
    "    nbatches = len(test_data)\n",
    "    nbatch_id = 0\n",
    "    for batch in test_data:\n",
    "        enc_classifier.zero_grad()\n",
    "        autoencoder.zero_grad()\n",
    "        source, target, lengths, tags = batch\n",
    "        source = to_gpu(True, Variable(source))\n",
    "        target = to_gpu(True, Variable(target)) # word ID\n",
    "        tags = to_gpu(True, Variable(tags))\n",
    "\n",
    "        # autoencoder encoded\n",
    "        # output_encode_only = autoencoder.encode(source, lengths, noise=False)\n",
    "        output_encode_only = autoencoder(source, lengths, noise=False, encode_only=True)\n",
    "        output_encode_only.retain_grad()\n",
    "    \n",
    "        # classifier output\n",
    "        output_classifier = enc_classifier(output_encode_only)\n",
    "        _, output_classifier_argmax = torch.max(output_classifier, -1)\n",
    "        classifier_loss = criterion_ce(output_classifier, tags)\n",
    "        classifier_loss.backward()\n",
    "        \n",
    "        encoder_output_grad = torch.sign(output_encode_only.grad.data)\n",
    "\n",
    "        x_adversarial = to_gpu(True, Variable(output_encode_only - epsilon * encoder_output_grad, requires_grad=False))\n",
    "        y_adversarial = enc_classifier(x_adversarial)\n",
    "        _, y_adversarial = torch.max(y_adversarial, -1)\n",
    "        all_accuracies += \\\n",
    "                torch.mean(y_adversarial.eq(tags).float()).item()\n",
    "        \n",
    "        # autoencoder decode\n",
    "        # batch x max_len\n",
    "        output = autoencoder.generate(hidden=x_adversarial, maxlen=lengths[0], sample=False)\n",
    "        # reshape\n",
    "        flattened_output = output.view(-1)\n",
    "\n",
    "        mask = target.gt(0)\n",
    "        masked_target = target.masked_select(mask)\n",
    "        \n",
    "        masked_output = \\\n",
    "            flattened_output.masked_select(mask)\n",
    "        assert masked_output.shape == masked_target.shape\n",
    "\n",
    "        w_ac = torch.mean(masked_output.eq(masked_target).float()).item()\n",
    "        word_accuracies += w_ac\n",
    "#         print(w_ac)\n",
    "#         print(masked_output.data.cpu().numpy())\n",
    "#         print(masked_target.data.cpu().numpy())\n",
    "        # bleu return (bleu, precisions, bp, ratio, translation_length, reference_length)\n",
    "        bb, _, _, _, _, _ = compute_bleu([[masked_target.data.cpu().numpy()]], \\\n",
    "                                         [masked_output.data.cpu().numpy()], max_order=2)\n",
    "        bleus += bb\n",
    "        \n",
    "        # example sentence\n",
    "        truncated_sent = []\n",
    "        for idx in masked_target.data:\n",
    "            # generated sentence\n",
    "            w = idx2word[idx.item()]\n",
    "            # truncate sentences to first occurrence of <eos>\n",
    "            if w != '<eos>':\n",
    "                truncated_sent.append(w)\n",
    "            else:\n",
    "                break\n",
    "        sent = \" \".join(truncated_sent)\n",
    "        real_tag = tags.data.cpu().numpy()[0]\n",
    "        if not real_sent_printed: original_sentences.append((real_tag, sent))\n",
    "    #     print(real_tag, sent, \"\\n\", '-'*20) if not real_sent_printed else print(\"\")\n",
    "        truncated_sent = []\n",
    "        for idx in masked_output.data:\n",
    "            # generated sentence\n",
    "            w = idx2word[idx.item()]\n",
    "            # truncate sentences to first occurrence of <eos>\n",
    "            if w != '<eos>':\n",
    "                truncated_sent.append(w)\n",
    "            else:\n",
    "                break\n",
    "        sent = \" \".join(truncated_sent)\n",
    "        pred_tag = y_adversarial.data.cpu().numpy()[0]\n",
    "    #     print(pred_tag, sent)\n",
    "        try: changed_sentences[nbatch_id]\n",
    "        except: changed_sentences.append([])\n",
    "        changed_sentences[nbatch_id].append((pred_tag, sent))\n",
    "        nbatch_id += 1\n",
    "    print(\"eps: {:.5f} acc: {:.5f} w_acc: {:.7f} bleu: {:.4f}\".format( \\\n",
    "                epsilon, all_accuracies/nbatches, word_accuracies/nbatches, bleus/nbatches))\n",
    "    real_sent_printed = True\n",
    "    if (all_accuracies/len(test_data)) > 0.99998:\n",
    "        print(\"Max accuracy. Break.\")\n",
    "        break\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# # replace @@s\n",
    "# # !sed -i.bak -r 's/(@@ )|(@@ ?$)//g' senti_flip_examples_xzhang.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
